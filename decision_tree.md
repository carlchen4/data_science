## 1️⃣ 熵（Entropy）

度量一个数据集的不确定性：

$$
H(D) = - \sum_{k=1}^{K} p_k \log_2(p_k)
$$

* $D$：当前节点的数据集
* $K$：类别数（信用风险里通常是 2：违约/不违约）
* $p_k$：类别 $k$ 在节点中所占比例

📌 熵越大 → 数据越混乱；熵越小 → 数据越纯。

---

## 2️⃣ 信息增益（Information Gain, ID3 用）

某个特征 $A$ 的分裂效果：

$$
Gain(D, A) = H(D) - \sum_{v=1}^{V} \frac{|D_v|}{|D|} H(D_v)
$$

* $V$：特征 $A$ 的可能取值个数
* $D_v$：按特征 $A=v$ 分裂后的子集
* $|D_v|$：子集大小

📌 **信息增益越大 → 特征越好**。

---

## 3️⃣ 基尼指数（Gini Index, CART 用）

另一种纯度度量：

$$
Gini(D) = 1 - \sum_{k=1}^{K} p_k^2
$$

* 完全纯（全部同一类） → Gini = 0
* 类别均匀混合 → Gini 最大（例如二分类时 Gini=0.5）。

CART 算法选择使得 **加权 Gini 最小** 的特征。

---

## 4️⃣ 信息增益率（Gain Ratio, C4.5 用）

为避免特征取值多时偏向性问题，引入**信息增益率**：

$$
GainRatio(D, A) = \frac{Gain(D, A)}{IV(A)}
$$

其中：

$$
IV(A) = - \sum_{v=1}^{V} \frac{|D_v|}{|D|} \log_2 \frac{|D_v|}{|D|}
$$

---

## 5️⃣ 通用流程（每次迭代）

1. 在当前节点数据集 $D$ 上：

   * 计算 $H(D)$ 或 $Gini(D)$。
2. 对每个特征 $A$：

   * 计算分裂后的加权熵/基尼。
   * 计算信息增益 / 基尼减少量。
3. 选择最优特征做分裂。
4. 对子集递归重复以上步骤。


决策树在银行业应用非常广泛，因为它的结果直观、容易解释，特别适合需要合规和业务人员能够理解的场景。下面我给你分几类场景说明：

---

## 📌 1. 信用风险管理（Credit Risk Management）

* **贷款审批（Loan Approval）**
  银行通过客户的收入、年龄、工作年限、负债率、信用评分等信息，训练决策树模型，判断客户是否有较高的违约风险。

  * 输入特征：年收入、房贷负担、信用历史、负债比率等
  * 输出：批准 / 拒绝
  * 好处：简单规则 → 比如“收入 < 30k 且 负债比率 > 50% → 高风险 → 拒绝贷款”

* **违约预测（Default Prediction, PD模型）**
  决策树可以用来预测客户在未来 12 个月是否可能违约，帮助银行计算风险资本。

---

## 📌 2. 欺诈检测（Fraud Detection）

* 信用卡欺诈交易识别：
  决策树模型可以根据**交易金额、交易地点、交易频率、设备信息**等来判断交易是否异常。

  * 例如：

    * “客户平时在加拿大消费，突然在巴西刷了大额交易 → 标记为高风险”
  * 好处：决策树可以很快分裂出关键的“风险分支”，用于实时监控。

---

## 📌 3. 营销与客户管理（Marketing & CRM）

* **精准营销（Targeted Marketing）**
  银行可以用客户数据（存款余额、是否有房贷、年龄、产品使用情况）来建决策树，预测客户是否可能购买新产品（如基金、保险、定期存款）。

  * 例子：

    * “年龄 > 35 且 有房贷 → 更可能购买保险产品”
  * 好处：帮助银行优化电话营销、邮件营销的目标群体，提高转化率。

* **客户流失预测（Churn Prediction）**
  通过客户的使用频率、投诉记录、账户余额变动等特征，决策树可以预测客户是否可能流失，从而提前采取措施挽留。

---

## 📌 4. 合规与反洗钱（AML, Compliance）

* **可疑交易报告（STR）**
  决策树模型可以学习哪些交易模式最可能触发“可疑交易”。例如：

  * 短时间内大量小额交易汇出境外
  * 客户职业与收入水平不符的大额资金流入

---

## 📌 5. 内部管理（Operational Risk）

* 决策树也可以用来预测银行内部的操作风险事件，例如系统宕机、流程错误、人员操作失误的发生概率。

---

✅ **总结**：

* 决策树在银行里的优势：

  * **可解释性强**：合规要求高的行业特别需要“能解释为什么拒绝/批准”。
  * **规则清晰**：便于转化为业务规则引擎。
  * **计算效率高**：适合大规模客户快速评分。
* 局限性：

  * 单一决策树容易过拟合 → 银行实际常用 **随机森林、XGBoost** 等集成方法来提升效果。


这就要看 **你用的模型类型** 和 **特征的分布**了。💡

---

## 1️⃣ 决策树类模型（Decision Tree / Random Forest / XGBoost）

* **不需要归一化 / 标准化**
* 原因：决策树是通过 **特征的阈值切分（`<=` 或 `>`）** 来做分裂的，不关心特征的绝对尺度。

  * 例子：`Income <= 50000` 或 `CreditScore <= 600`
* 树模型关注的是**相对大小**，而不是数值的具体范围
* **归一化/标准化不会影响树的分裂和预测结果**

✅ 所以对于你这类银行贷款违约预测，用决策树、随机森林、XGBoost 时，不必做 normalization。

---

## 2️⃣ 对需要归一化的模型

如果换成其他模型，比如：

| 模型                   | 是否需要归一化 | 原因                   |
| -------------------- | ------- | -------------------- |
| Logistic Regression  | ✅ 是     | 梯度下降收敛速度快，特征尺度影响系数大小 |
| SVM                  | ✅ 是     | 核函数计算距离，尺度不同会影响超平面   |
| KNN                  | ✅ 是     | 距离度量受特征绝对值影响         |
| 神经网络                 | ✅ 是     | 梯度下降训练时，数值范围影响收敛     |
| 决策树 / 随机森林 / XGBoost | ❌ 否     | 只关心阈值切分，尺度无关         |

---

## 3️⃣ 小结

* **树模型 → 不需要 normalization**
* **基于距离或梯度优化的模型 → 需要 normalization / 标准化**
* 在实际银行信用风险建模中：

  * 决策树 / 随机森林 / XGBoost 很常用 → 一般不做 normalization
  * 逻辑回归 / SVM / 神经网络 → 需要做 scaling

---

如果你愿意，我可以帮你画一个 **图示对比**，展示决策树和逻辑回归为什么对数值范围敏感或不敏感，让你一眼就能理解。

你想让我画吗？


Reference:

* https://www.atmosp.physics.utoronto.ca/~shahnas/Courses/Machine_Learning_Grad/Lecture_09.pdf 
