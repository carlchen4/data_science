{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 136117,
          "sourceType": "datasetVersion",
          "datasetId": 68150
        }
      ],
      "dockerImageVersionId": 22557,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Bank Full Machine Learning",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlchen4/data_science/blob/main/Bank_Full_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "sonujha090_bank_marketing_path = kagglehub.dataset_download('sonujha090/bank-marketing')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "VZtr1Gofat9G"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About This File"
      ],
      "metadata": {
        "_uuid": "0a663bc5d6f1d1e94d43cb2a60e896490fad561e",
        "id": "kNqvDpVfat9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Title: Bank Marketing\n",
        "\n",
        "Sources Created by: Paulo Cortez (Univ. Minho) and Sérgio Moro (ISCTE-IUL) @ 2012\n",
        "\n",
        "Past Usage:\n",
        "\n",
        "The full dataset was described and analyzed in:\n",
        "\n",
        "S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.\n",
        "\n",
        "Relevant Information:\n",
        "\n",
        "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (or not) subscribed.\n",
        "\n",
        "There are two datasets: 1) bank-full.csv with all examples, ordered by date (from May 2008 to November 2010). 2) bank.csv with 10% of the examples (4521), randomly selected from bank-full.csv. The smallest dataset is provided to test more computationally demanding machine learning algorithms (e.g. SVM).\n",
        "\n",
        "The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
        "\n",
        "Number of Instances: 45211 for bank-full.csv (4521 for bank.csv)\n",
        "\n",
        "Number of Attributes: 16 + output attribute.\n",
        "\n",
        "Attribute information:\n",
        "\n",
        "For more information, read [Moro et al., 2011].\n",
        "\n",
        "Input variables:\n",
        "\n",
        "bank client data:\n",
        "1 - age (numeric) 2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\", \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") 3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed) 4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\") 5 - default: has credit in default? (binary: \"yes\",\"no\") 6 - balance: average yearly balance, in euros (numeric) 7 - housing: has housing loan? (binary: \"yes\",\"no\") 8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
        "\n",
        "related with the last contact of the current campaign:\n",
        "9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") 10 - day: last contact day of the month (numeric) 11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\") 12 - duration: last contact duration, in seconds (numeric)\n",
        "\n",
        "other attributes:\n",
        "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact) 14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted) 15 - previous: number of contacts performed before this campaign and for this client (numeric) 16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
        "\n",
        "Output variable (desired target): 17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n",
        "\n",
        "Missing Attribute Values: None"
      ],
      "metadata": {
        "_uuid": "376e134edd0753f619eb2472d4f50f70f525a9b1",
        "id": "8dqVHgKxat9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "_uuid": "f733bee9a660e458f4ea9d3540d4f8b252777d30",
        "id": "s11KFnxfat9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Dataset is a big challenge for a Data Scientist. Besides being unbalanced data, further, we will realize that some datasets don't have a solution. And so, take more information and data become crucial to solve the Data Science problem."
      ],
      "metadata": {
        "_uuid": "8ad57787ebb7cd13c1d9b28c9b75bf13dfc447f9",
        "id": "Dm2O3wQnat9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import random\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "WD7CD5ewat9N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Dataset\n",
        "df = pd.read_csv(\"../input/bank-full.csv\")"
      ],
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "c4K4zWPAat9N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating User Columns\n",
        "df_user = pd.DataFrame(np.arange(0,len(df)), columns=['user'])\n",
        "df = pd.concat([df_user, df], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "eba5cd0ec3a66851bdaf3625342c8d22ffe7b7d4",
        "id": "6PcMHUmyat9O"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "c3d0c778fe35909ee331936f271964df728e849f",
        "id": "zXkIawxCat9O"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "d607b71b2068d9a5742d82f662c6f2f3be784cfc",
        "id": "5KqsiDxcat9P"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "2b0602753fb88163f7716bcdd87e725c0c79188f",
        "id": "044haOjXat9Q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns.values"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "dc2ae86f25651720f23ea09b99d41d85300c7c4f",
        "id": "6cPAYQ2hat9Q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis"
      ],
      "metadata": {
        "_uuid": "1168bcee52e92477cc7c42022bb18a57880b9948",
        "id": "zxNqLP0wat9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "d98af795618adb835a38e9696c03f80bedb4dec8",
        "id": "cb_2Rsrjat9R"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('y').mean()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "f2ff1f26846292df92cedf8df14c0836f5db07ec",
        "id": "MSPFviUGat9R"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note below how Dataset is unbalanced"
      ],
      "metadata": {
        "_uuid": "2740c1afb44abbf739a0ad537128d23b5008de23",
        "id": "rgDZXxQGat9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "2c88de80cc6f859f1f3db4b92efdaaa07e348eb5",
        "id": "bgDTjSDUat9S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "countNo = len(df[df.y == 'no'])\n",
        "countYes = len(df[df.y == 'yes'])\n",
        "print('Percentage of \"No\": {:.3f}%'. format((countNo/(len(df.y))*100)))\n",
        "print('Percentage of \"Yes\": {:.3f}%'. format((countYes/(len(df.y))*100)))"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "14217c806e857eb3e770fef2e4bcdd121d6d1fe2",
        "id": "WYMFJ1TBat9S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verifying Null Values"
      ],
      "metadata": {
        "_uuid": "8550307d2fe6260a01411336df23d0b1e9d134ec",
        "id": "FLkydUCWat9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verifying null values\n",
        "sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "5e145813e05132c68db906165d7aa203e1ecbe22",
        "id": "JjH3hOkMat9S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().any()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "b257579cf68e3f7caf83d667b80815ff50cf1c22",
        "id": "wqvIoEcJat9S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "f2137e6ed6c8266a4a1ef2a3982bb6eef1992323",
        "id": "aM_P3A3Tat9S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define X and y"
      ],
      "metadata": {
        "_uuid": "38ad42a4fe54ecc58d82f82992cf8f206d4b1de5",
        "id": "fiu7AQttat9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define X and y\n",
        "X = df.drop(['y','user','job','marital', 'education', 'contact',\n",
        "             'housing', 'loan', 'day', 'month', 'poutcome' ], axis=1)\n",
        "y = df['y']"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "2935daa33b97f838798822af73efa76b85f52c0e",
        "id": "OBfFP4Zlat9T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Dummies Values"
      ],
      "metadata": {
        "_uuid": "1b446e3caa46ee97dddc085f05a2ab95eadbcac1",
        "id": "N65nJ9fwat9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(X)\n",
        "y = pd.get_dummies(y)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "b3eb23aa5c151ec8152f51b14b42b954aeae7971",
        "id": "RmEICNTzat9T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dummy Trap"
      ],
      "metadata": {
        "_uuid": "0c1b23b18a6d0e748056f84d01ffd9e45b21760e",
        "id": "2uz8qfinat9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dummy Variable Trap can influence negatively in our analyses. Dummy Variable trap is a scenario in which the independent variables are multicollinear - a scenario in which two or more variables are highly correlated; in simple terms, one variable can be predicted from the others. The best definition for Dummy Variable Trap [here](http://www.youtube.com/watch?v=qrWx3OjZL3o)\n"
      ],
      "metadata": {
        "_uuid": "c82fbd392d2878ae6b2c925618f30720be558041",
        "id": "5SiGiAFNat9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns\n",
        "X = X.drop(['default_no'], axis= 1)\n",
        "X = X.rename(columns = {'default_yes': 'default'})\n",
        "y.columns\n",
        "y = y.drop(['yes'], axis=1)\n",
        "y = y.rename(columns= {'no': 'y'})"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "2b9e3f282b7186071f352808f444cf23c97a0748",
        "id": "s9XCLn3iat9T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualising Data"
      ],
      "metadata": {
        "_uuid": "df6560a25a84d7fae1aa1619ed27dc251a5801f8",
        "id": "YvpaxfSyat9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Age group\n",
        "bins = range(0, 100, 10)\n",
        "ax = sns.distplot(df.age[df.y=='yes'],\n",
        "              color='red', kde=False, bins=bins, label='Have Subscribed')\n",
        "sns.distplot(df.age[df.y=='no'],\n",
        "         ax=ax,  # Overplots on first plot\n",
        "         color='blue', kde=False, bins=bins, label=\"Haven't Subscribed\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "94f4fba111eb4edad809ed2d3409849b2142aefb",
        "id": "UNC3jnECat9T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Age\n",
        "pd.crosstab(df.age,df.y).plot(kind=\"bar\",figsize=(20,6))\n",
        "plt.title('Client Subscribed Frequency for Ages')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "372fd505c44c33390e7b45a393c542169d22dc13",
        "id": "tl7in096at9U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df.marital,df.y).plot(kind=\"bar\",figsize=(15,6),color=['#1CA53B','#AA1111' ])\n",
        "plt.title('Client Subscribed Frequency for Maritial')\n",
        "plt.xlabel('marital')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend([\"Haven't Subscribed\", \"Have Subscribed\"])\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "ad01852e314ec5ff0e417dc44941f0d61860ddd3",
        "id": "5U4ScSP3at9U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x=df.age[df.y=='yes'], y=df.duration[(df.y=='yes')], c=\"red\")\n",
        "plt.scatter(x=df.age[df.y=='no'], y=df.duration[(df.y=='no')])\n",
        "plt.legend([\"Have Subscribed\", \"Haven't Subscribed\"])\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Duration\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "70b68da9930f57db9e10752beeba97f2cfff5798",
        "id": "a23u-NAdat9U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data=df, hue='y', vars= ['age', 'balance', 'duration'])"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "f0bf69cb0268337bad01fd9f52673860dc3da5bc",
        "id": "Hf_tr1KFat9U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='y', data=df, label='Count')"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "8bdb443d6387c70edb5a939b8d09a9000d9e2c6d",
        "id": "x1_iaIYBat9U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='age', y='balance',hue='y', data=df)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "3c90631e471e9c5e7c790c13442e1b722f43178c",
        "id": "xHZpi7kIat9U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(data=df.corr(), annot=True, cmap='viridis')"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "3dc2d2b89d9cadc79748ed05b053bb18a776fea3",
        "id": "MR6GyjcQat9V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df.age, bins = 20)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "d10d706e7908320f35e99c2be1f2e1c201472eca",
        "id": "cIrQYthiat9V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df.balance, bins = 20)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "0704bf797e77eaaf6be27a0c4be236796f9338d8",
        "id": "1Xo9kxKzat9Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df.duration, bins = 20)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "cce1137d2a659f7ea5097a5cf8b0135057eb30ee",
        "id": "mM2o8Nudat9Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = X\n",
        "fig = plt.figure(figsize=(15, 12))\n",
        "plt.suptitle('Histograms of Numerical Columns', fontsize=20)\n",
        "for i in range(df2.shape[1]):\n",
        "    plt.subplot(6, 3, i + 1)\n",
        "    f = plt.gca()\n",
        "    f.set_title(df2.columns.values[i])\n",
        "\n",
        "    vals = np.size(df2.iloc[:, i].unique())\n",
        "    if vals >= 100:\n",
        "        vals = 100\n",
        "\n",
        "    plt.hist(df2.iloc[:, i], bins=vals, color='#3F5D7D')\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "097a85d112a8eff0409a3f8ac9c6cc16e7b97dcc",
        "id": "7smM6xpyat9Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Correlation with independent Variable\n",
        "df2.corrwith(y.y).plot.bar(\n",
        "        figsize = (10, 10), title = \"Correlation with Y\", fontsize = 15,\n",
        "        rot = 45, grid = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "d541b539340ad8ec5865c117a67471e1dfcb4baa",
        "id": "eYMFJJbPat9a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Correlation Matrix\n",
        "sns.set(style=\"white\")\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = df2.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "ac3340816b44e3a31ac3c171f7c16f4bc87b97df",
        "id": "JVAe3eG0at9a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Pie Plots\n",
        "df.columns\n",
        "df2 = df[['y','job','marital', 'education', 'default', 'housing','loan', 'contact',\n",
        "             'month', 'poutcome'\n",
        "                    ]]\n",
        "fig = plt.figure(figsize=(15, 12))\n",
        "plt.suptitle('Pie Chart Distributions', fontsize=20)\n",
        "for i in range(1, df2.shape[1] + 1):\n",
        "    plt.subplot(6, 3, i)\n",
        "    f = plt.gca()\n",
        "    f.axes.get_yaxis().set_visible(False)\n",
        "    f.set_title(df2.columns.values[i - 1])\n",
        "\n",
        "    values = df2.iloc[:, i - 1].value_counts(normalize = True).values\n",
        "    index = df2.iloc[:, i - 1].value_counts(normalize = True).index\n",
        "    plt.pie(values, labels = index, autopct='%1.1f%%')\n",
        "    plt.axis('equal')\n",
        "fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "9bed86c97bb23c4178b8d724bba0af5e8ad99e26",
        "id": "2AZhGaAlat9a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the Dataset into Training Set and Test Set"
      ],
      "metadata": {
        "_uuid": "6ce4978c947b7560a923ccede74317f7b8dea592",
        "id": "od0CFLfXat9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "4c2c350b2e2e461a0ba246a29d197b41cc5603ce",
        "id": "Pum_f_vrat9a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "eba0540036acd4d1d388324ab633891cda500b45",
        "id": "TgcIrXbFat9b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balancing the Traing Set"
      ],
      "metadata": {
        "_uuid": "e4725fe32e682b3faa4cc4b18acf010a8e7b48d3",
        "id": "x3reFvkhat9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Training Set is unbalanced. And so become necessary to organize it."
      ],
      "metadata": {
        "_uuid": "98661570f16934d2ba0746b772b2928f0f99ebc3",
        "id": "jd6GtFkXat9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train['y'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "3b8384c69e6155e7f1046b5c57a0fe3e53367918",
        "id": "58zjs6mNat9b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pos_index = y_train[y_train.values == 1].index\n",
        "neg_index = y_train[y_train.values == 0].index\n",
        "\n",
        "if len(pos_index) > len(neg_index):\n",
        "    higher = pos_index\n",
        "    lower = neg_index\n",
        "else:\n",
        "    higher = neg_index\n",
        "    lower = pos_index\n",
        "\n",
        "random.seed(0)\n",
        "higher = np.random.choice(higher, size=len(lower))\n",
        "lower = np.asarray(lower)\n",
        "new_indexes = np.concatenate((lower, higher))\n",
        "\n",
        "X_train = X_train.loc[new_indexes]\n",
        "y_train = y_train.loc[new_indexes]"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "f39f7964cdaadbcb33ed54c8f0a93ef76fb10400",
        "id": "AhLwL67yat9c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_train['y'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "128cab657bac03a0bb530f4da7c12978120c76c4",
        "id": "h6gOdqGZat9c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling"
      ],
      "metadata": {
        "_uuid": "5e19fac9d0e56f3709e985b0ef0e7f5ba84e99e9",
        "id": "-Qt8Zy5Zat9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train2 = pd.DataFrame(sc.fit_transform(X_train))\n",
        "X_test2 = pd.DataFrame(sc.transform(X_test))\n",
        "X_train2.columns = X_train.columns.values\n",
        "X_test2.columns = X_test.columns.values\n",
        "X_train2.index = X_train.index.values\n",
        "X_test2.index = X_test.index.values\n",
        "X_train = X_train2\n",
        "X_test = X_test2"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "214188c8c2f25e6f341818933804872962f625ad",
        "id": "3dlX-iSlat9c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building\n",
        "# Comparing Models"
      ],
      "metadata": {
        "_uuid": "bb8340abfdae83c56f63d94e3eff340bb2719476",
        "id": "u3yEa9kFat9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0, penalty = 'l1')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "results = pd.DataFrame([['Logistic Regression (Lasso)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "0f32cb46254050805a070ba84300f3d047cd50e4",
        "id": "pf-3UY5Xat9d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## K-Nearest Neighbors (K-NN)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=15, metric='minkowski', p= 2)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['K-Nearest Neighbors (minkowski)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "30d0efb2da7e09f3159ad2023e5c4b157c709b47",
        "id": "XaGKU52Rat9d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## SVM (Linear)\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(random_state = 0, kernel = 'linear', probability= True)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "010b25699a57030e8a7518cc7c59ea36715c8fd3",
        "id": "CwB4FpCqat9d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## SVM (rbf)\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(random_state = 0, kernel = 'rbf', probability= True)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['SVM (RBF)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "425414a5e04f45f7909b3e9f132a8b8eca3e9a2d",
        "id": "t_kQqIWVat9d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Naive Bayes (Gaussian)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "91241878e52cc096ba48a37244fedb9824d868da",
        "id": "HE9_5ISiat9e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "#Predicting the best set result\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Decision Tree', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "6ef983937aede84cf54c77ea30d6f090ea82fbe2",
        "id": "wbkNbYjAat9e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Random Forest Gini (n=100)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n",
        "                                    criterion = 'gini')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest Gini (n=100)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "54f2b219ff65a0cc66dfda45a8b0643285e2fd54",
        "id": "LineAJySat9e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Random Forest Gini (n=200)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state = 0, n_estimators = 200,\n",
        "                                    criterion = 'gini')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest Gini (n=200)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "dcf4ea5fd632c29f63b634101c1bd945c594f072",
        "id": "4zHNW4B0at9e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Random Forest Gini (n=300)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state = 0, n_estimators = 300,\n",
        "                                    criterion = 'gini')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest Gini (n=300)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "a77c106bce1f2bfddba6a12f3aa8fa27711e4b42",
        "id": "fTyQT-iJat9j"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Random Forest Entropy (n=100)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n",
        "                                    criterion = 'entropy')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest Entropy (n=100)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "6c1d0c39f3da1d12ffc1d6c2cad3fbf2392354c5",
        "id": "gVhC5CWBat9k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Random Forest Entropy (n=200)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state = 0, n_estimators = 200,\n",
        "                                    criterion = 'entropy')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest Entropy (n=200)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "b49d5f8096ed72048677192169bf633e5e5ca96a",
        "id": "QdnOZKxPat9k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Random Forest Entropy (n=300)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state = 0, n_estimators = 300,\n",
        "                                    criterion = 'entropy')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest Entropy (n=300)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "29512e15d7406a6a0435af9aadc3ec3ac1890a4f",
        "id": "fwgNKYJqat9k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "_uuid": "20a87b4bec5d452144bc7996eaffbf8cd3f7d295",
        "id": "4EtqnDuVat9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SVM (Linear) was the most powerful method for our model as shown below."
      ],
      "metadata": {
        "_uuid": "c29841602b55aaa34b3f81cc9db5c7b6cbeb2a37",
        "id": "BhIBv-qlat9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "017e0ab4af5ed12e40879958b4831dc4fd1abf8f",
        "id": "aEEIK4-fat9k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying K-fold Validation"
      ],
      "metadata": {
        "_uuid": "418891430fc787b4cc12268e4b0c5e586e0ab71e",
        "id": "pXeIEjIlat9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train,cv=10)\n",
        "accuracies.mean()\n",
        "accuracies.std()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "413b7e53de9fd54ce1215e7b3a812b799a29d961",
        "id": "Hv81Lbjsat9l"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM (Linear) Accuracy: %0.3f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "2ee19712fd888aedb64293c30777f3861f7d0c38",
        "id": "klI8_p_Dat9l"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\n",
        "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(df_cm, annot=True, fmt='g')\n",
        "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "6c6d1c947a4499c5e7a6e47cc28d2488b6e71c9e",
        "id": "-3zKsFr_at9l"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy Paradox"
      ],
      "metadata": {
        "_uuid": "e0d9c72b068f483613699cdb69c34d3035ee3038",
        "id": "8OsapSQ2at9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy is not the best way to measure a perfomance of model. It´s because Accuracy Paradox. More about Accuracy Paradox [here](http://towardsdatascience.com/accuracy-paradox-897a69e2dd9b)."
      ],
      "metadata": {
        "_uuid": "e84f81f9ee6021ae1804800102c74a30f2b73be1",
        "id": "V9R93ENcat9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cumulative Accuracy Profile (CAP)"
      ],
      "metadata": {
        "_uuid": "bde19fb9863270c7cff60b44d33a4430657dbb1e",
        "id": "BbrxLwjAat9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For figure out Accuracy Paradox, we will use the Cumulative Accuracy Profile (CAP). More about Cumulative Accuracy Profile (CAP) [here](http://en.wikipedia.org/wiki/Cumulative_accuracy_profile)."
      ],
      "metadata": {
        "_uuid": "fd2f565c58fd88cab287f278372d3353e5f48f5c",
        "id": "c_8ZKmOOat9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cumulative Accuracy Profile"
      ],
      "metadata": {
        "_uuid": "078d0431d92fc5e8596971388e0a1403c7269fd6",
        "id": "-A3gWTI1at9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Cumulative Accuracy Profile (CAP)\n",
        "y_pred_proba = classifier.predict_proba(X=X_test)\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import integrate\n",
        "def capcurve(y_values, y_preds_proba):\n",
        "    num_pos_obs = np.sum(y_values)\n",
        "    num_count = len(y_values)\n",
        "    rate_pos_obs = float(num_pos_obs) / float(num_count)\n",
        "    ideal = pd.DataFrame({'x':[0,rate_pos_obs,1],'y':[0,1,1]})\n",
        "    xx = np.arange(num_count) / float(num_count - 1)\n",
        "\n",
        "    y_cap = np.c_[y_values,y_preds_proba]\n",
        "    y_cap_df_s = pd.DataFrame(data=y_cap)\n",
        "    y_cap_df_s = y_cap_df_s.sort_values([1], ascending=False).reset_index(level = y_cap_df_s.index.names, drop=True)\n",
        "\n",
        "    print(y_cap_df_s.head(20))\n",
        "\n",
        "    yy = np.cumsum(y_cap_df_s[0]) / float(num_pos_obs)\n",
        "    yy = np.append([0], yy[0:num_count-1]) #add the first curve point (0,0) : for xx=0 we have yy=0\n",
        "\n",
        "    percent = 0.5\n",
        "    row_index = int(np.trunc(num_count * percent))\n",
        "\n",
        "    val_y1 = yy[row_index]\n",
        "    val_y2 = yy[row_index+1]\n",
        "    if val_y1 == val_y2:\n",
        "        val = val_y1*1.0\n",
        "    else:\n",
        "        val_x1 = xx[row_index]\n",
        "        val_x2 = xx[row_index+1]\n",
        "        val = val_y1 + ((val_x2 - percent)/(val_x2 - val_x1))*(val_y2 - val_y1)\n",
        "\n",
        "    sigma_ideal = 1 * xx[num_pos_obs - 1 ] / 2 + (xx[num_count - 1] - xx[num_pos_obs]) * 1\n",
        "    sigma_model = integrate.simps(yy,xx)\n",
        "    sigma_random = integrate.simps(xx,xx)\n",
        "\n",
        "    ar_value = (sigma_model - sigma_random) / (sigma_ideal - sigma_random)\n",
        "\n",
        "    fig, ax = plt.subplots(nrows = 1, ncols = 1)\n",
        "    ax.plot(ideal['x'],ideal['y'], color='grey', label='Perfect Model')\n",
        "    ax.plot(xx,yy, color='red', label='User Model')\n",
        "    ax.plot(xx,xx, color='blue', label='Random Model')\n",
        "    ax.plot([percent, percent], [0.0, val], color='green', linestyle='--', linewidth=1)\n",
        "    ax.plot([0, percent], [val, val], color='green', linestyle='--', linewidth=1, label=str(val*100)+'% of positive obs at '+str(percent*100)+'%')\n",
        "\n",
        "    plt.xlim(0, 1.02)\n",
        "    plt.ylim(0, 1.25)\n",
        "    plt.title(\"CAP Curve - a_r value =\"+str(ar_value))\n",
        "    plt.xlabel('% of the data')\n",
        "    plt.ylabel('% of positive obs')\n",
        "    plt.legend()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "0c8935f05c649d79b3d33cdd07434d662ec15c23",
        "id": "pv7ntos6at9m"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "capcurve(y_test,y_pred_proba[:,1])"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "69049e24a70f37ba90b4878b8c91b368c40f852d",
        "id": "6L4-LXvwat9m"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note how the CAP result was much smaller than Accuracy result. CAP (55.25%) versus Accuracy (75.54%). Definitely the Accuracy Paradox influence negatively the model."
      ],
      "metadata": {
        "_uuid": "adcfe24bd38cc7836e1cf036a8d8ac697980988d",
        "id": "ZaUdUkaUat9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing Coefficients\n",
        "pd.concat([pd.DataFrame(X_train.columns, columns = [\"features\"]),\n",
        "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
        "           ],axis = 1)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "f52fc1cd6dd142b01c92340247789f939dd548d8",
        "id": "k-9IjLecat9n"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection\n",
        "# Recursive Feature Elimination"
      ],
      "metadata": {
        "_uuid": "be4b4120b9f4edeb3fb3095ede7bfda5abb15881",
        "id": "04T-Yi4Pat9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For feature selection, we wil use the Recursive Feature Elimination (RFE). More about Recursive Feature Elimination (RFE) [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)."
      ],
      "metadata": {
        "_uuid": "a8d5d0ff2b2c5e133d80dd76bd09a16ff1262727",
        "id": "WlVbqQdCat9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursive Feature Elimination\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Model to Test\n",
        "classifier = SVC(random_state = 0, kernel = 'linear', probability= True)\n",
        "\n",
        "# Select Best X Features\n",
        "rfe = RFE(classifier, n_features_to_select=None)\n",
        "rfe = rfe.fit(X_train, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "ed36ccb4b1b72def7c7157d19413e9322fb710f8",
        "id": "Nff8RP2gat9o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the selection of the attributes\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "2f65c7b9cb9dd04ae201b871ffeff771fac9476a",
        "id": "dQlHiELQat9o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns[rfe.support_]"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "f172fad2e773b2f0951bf81a7e630a2ae4e63372",
        "id": "USIdbrmeat9o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# New Correlation Matrix\n",
        "sns.set(style=\"white\")\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = X_train[X_train.columns[rfe.support_]].corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(18, 15))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "04418fd5e1858182dee7896b082f89844ac090fd",
        "id": "SAxdjxIxat9o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting Model to the Training Set\n",
        "classifier = SVC(random_state = 0, kernel = 'linear', probability= True)\n",
        "classifier.fit(X_train[X_train.columns[rfe.support_]], y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test[X_train.columns[rfe.support_]])\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['SVM RFE (Linear)', acc, prec, rec, f1]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "6df2950414dca2abde289dbb6da439a4cea9c5d3",
        "id": "7oGazhyYat9o"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking off some features, our model decreases a little bit the Accuracy as shown below."
      ],
      "metadata": {
        "_uuid": "2895a0db8993ba7ce18e7f43eafb88a426c607b0",
        "id": "7-S72uEOat9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "35664ba860d45870447558f98b461099bdc05c20",
        "id": "OpufudmEat9p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating Results\n",
        "#Making the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "sns.heatmap(data=cm, annot=True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "146c2b11d9002a49380ba14612ed5c8dc7bd494a",
        "id": "SVP-uhDuat9p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Making the classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "f245951d0a0c361d9e08f2e190c772c71cbd3933",
        "id": "o3_IeK3jat9p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying k-Fold Cross Validation (RFE)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier,\n",
        "                             X = X_train[X_train.columns[rfe.support_]],\n",
        "                             y = y_train, cv = 10)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "2082f465a67ed17f9a8d0cb037d4de3adc662c6c",
        "id": "PZSbd5kuat9p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM RFE (Linear) Accuracy: %0.3f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "a3773d8eb3fe7bd7fc200dc33e569ce1c7869eb2",
        "id": "gVFZ_cUlat9p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing Coefficients\n",
        "pd.concat([pd.DataFrame(X_train[X_train.columns[rfe.support_]].columns, columns = [\"features\"]),\n",
        "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
        "           ],axis = 1)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "93703a2552c90d0fe3dcfc617c174db6d178277f",
        "id": "r5lqu6iHat9p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#CAP Curve\n",
        "y_pred_proba = classifier.predict_proba(X=X_test[X_train.columns[rfe.support_]])\n",
        "capcurve(y_test,y_pred_proba[:,1])"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "79251fe826b3a5ac19a69d9ebcd195bd9a39890b",
        "id": "XpQ_7rcYat9p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "### End of Model ####\n",
        "\n",
        "# Formatting Final Results\n",
        "user_identifier = df['user']\n",
        "final_results = pd.concat([y_test, user_identifier], axis = 1).dropna()\n",
        "final_results['predicted'] = y_pred\n",
        "final_results = final_results[['user', 'y', 'predicted']].reset_index(drop=True)"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "7719ab65ebd935cb4cac51fbff24d074196f18d6",
        "id": "BLIxSANbat9q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "final_results.head()"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "6cd94b4e648c3b6870fcff8f9e31a130be598078",
        "id": "wjjMX98Pat9q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "d8b4be2d1a9fb1ffcdcdc3edf6f215b52a9760d2",
        "id": "mxG6Ymvrat9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As observed, the Bank Marketing Dataset is unbalanced. And so become tough to perform pretty well the model. Another issue was the Accuracy Paradox that provides a false Accuracy final result. Nevertheless, the Cumulative Accuracy Profile showed that our model is performing very worst.\n",
        "For this case, perhaps more data can help balance the dataset and trying to find one best final result.\n",
        "Perfomance of Model Accuracy: 79.54%\n",
        "Cumulative Accuracy Profile: 55.25%"
      ],
      "metadata": {
        "_uuid": "78a2b5423669a2309bebf091428c4c160a8f918f",
        "id": "TyFW-iLiat9q"
      }
    }
  ]
}